{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning week - Day 1 - Your First Neural Network\n",
    "\n",
    "### Exercise objectives\n",
    "- Write your first Neural Network\n",
    "- Inspect some of the most important hyperparameters of Neural Networks\n",
    "\n",
    "<hr>\n",
    "<hr>\n",
    "\n",
    "\n",
    "In this exercise, you will build your first Neural Network that will separate two classes.\n",
    "Each data $X$ has only two coordinates $X = (x_1, x_2)$ and belongs to either the class 0 or to the class 1. It is called the `moons dataset`. \n",
    "\n",
    "As there are only two features, the points can be represented on a 2D-scatterplot, where the colors correspond to the two available classes: $\\color{blue}{blue}$ and $\\color{red}{red} $. Here is an example of such data : \n",
    "\n",
    "![Two moons](moons_example.png)\n",
    "\n",
    "\n",
    "\n",
    "## 1. Create data\n",
    "\n",
    "Here, we will use the scikit-learn `make_moons` function [(see documentation here)](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html) to create 2 moons that cannot be linearly separated. Each moon correspond to a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "### Data generation\n",
    "X, y = make_moons(n_samples=300, noise=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function allows to plot the two moons\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_moons(X, y):\n",
    "    df = pd.DataFrame(dict(x1=X[:,0], x2=X[:,1], label=y))\n",
    "    colors = {0:'red', 1:'blue'}\n",
    "    fig, ax = plt.subplots()\n",
    "    grouped = df.groupby('label')\n",
    "\n",
    "    for key, group in grouped:\n",
    "        group.plot(ax=ax, kind='scatter', x='x1', y='x2', label=key, color=colors[key])\n",
    "    plt.show()\n",
    "\n",
    "plot_moons(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì  Play with the number of samples and the noise to discover the effects on the `moons dataset`, by plotting the moons for different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Draw 250 samples of the data with a noise equal to 0.20 (random state being 0) and split the initial dataset into a train and test set (size: 70/30%)\n",
    "\n",
    "*Remark* : Please call the variables `X_train`, `y_train`, `X_test` and `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now define your first neural network.\n",
    "The architecture of your model should have : \n",
    "- a first layer with 5 neurons, with a `relu` activation function and the correct input dimension\n",
    "- a output layer suited to your 2-class classification task.\n",
    "\n",
    "\n",
    "‚ùì Complete the next function with the previous architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    ### Model architecture\n",
    "    pass  # YOUR CODE HERE\n",
    "    ### Model optimization : Optimizer, loss and metric    \n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = initialize_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùó **Remark** ‚ùó Briefly speaking, the **`.compile()`** tells your algorithm how to optimize the weights of your network once it will be fit on real data. **`binary_crossentropy`** is the \"log-loss\" that you have already seen in Machine-Learning.\n",
    "\n",
    "‚ùì How many parameters does the model have?  \n",
    "Double check using the **`.summary()`** function which displays the stack of layers, the shape of the output after each layer, and the number of parameters of each layer. Use this function to check that you have 21 parameters i.e. weights in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now ready to train your algorithm on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initialize_model()\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=100,\n",
    "                    batch_size=8,\n",
    "                    verbose=0) # Try different verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`history` contains information about the training.\n",
    "\n",
    "‚ùì Inspect all its attributes using `history.__dict__`. You will see epoch-by-epoch info stored in `history.history`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Plot the history of the train loss using the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('Train loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict & Evaluate performance on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can predict `y_pred` using the **`.predict()`** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the **`.evaluate()`** method to return the **`loss value`** &  and the **`performance metrics`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The first element corresponds to the **loss** value, set to `\"binary_crossentropy\"` in `model.compile()`. Its value is hard to interpret.\n",
    "\n",
    "- The second element is the **metrics**, that we set to `\"accuracy\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì What is your accuracy on the test test? Store the value as a `float` in the `accuracy` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Check your prediction visually by using our `plot_decision_regions` available in `utils/plots.py`. It looks a bit underfitted, right? We will create a deeper network next!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plots import plot_decision_regions\n",
    "plot_decision_regions(X,y, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult('first_model', accuracy=accuracy)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Relaunch the model on 500 iterations\n",
    "- Don't forget to call the `initialize_model` function, otherwise, your initial parameters will be those you have already learnt on the previous fit!!)\n",
    "- Plot the history to see how the loss changed over the different epochs/iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Did the test accuracy improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not necessarily...So when should we stop training a Deep Learning Model?\n",
    "Answer in the next chapter `Optimizers, Loss, Fitting` of this `Deep Learning Module` !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Let's try a **deeper** architecture that includes : \n",
    "\n",
    "- a first layer with 20 neurons (activation: `\"relu\"`)\n",
    "- a second layer with 10 neurons (activation: `\"relu\"`)\n",
    "- a third layer with 5 neurons (activation: `\"relu\"`)\n",
    "- an output layer suited for this problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model_2():\n",
    "    ### Model architecture\n",
    "    pass  # YOUR CODE HERE\n",
    "    ### Model optimization : Optimized, loss and metric\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = initialize_model_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì What is the number of parameters of your new model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run your model on the previous data with 500 epochs and plot the loss afterwards.  \n",
    "‚ùì What is your accuracy on the test test? Store it as `accuracy_deep` variable (`float`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Do you think we have overfitted on the noise? Check it out below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plots import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X_train,y_train, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult('deeper_model',\n",
    "                         accuracy=accuracy_deep)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ **Congratulations! Push and commmit this notebook before moving to the next**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}