{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a5d197",
   "metadata": {},
   "source": [
    "<big><big><big><b>NLP Lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2083af9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T17:03:55.133437Z",
     "start_time": "2021-11-03T17:03:54.137890Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0cb867",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec9b441c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'999 Football is my passion. I love to play with footballs!! Who else loves football?'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '999 Football is my passion. I love to play with footballs!! Who else loves football?'\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f84d2a3",
   "metadata": {},
   "source": [
    "## Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d83fc4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'999 football is my passion. i love to play with footballs!! who else loves football?'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = text.lower() \n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2bedc0",
   "metadata": {},
   "source": [
    "## Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "357ccad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''.join([letter for letter in text if not letter.isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0219450d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' football is my passion. i love to play with footballs!! who else loves football?'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ec7c32",
   "metadata": {},
   "source": [
    "## Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1a933d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string \n",
    "\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f662f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' football is my passion i love to play with footballs who else loves football'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for punctuation in string.punctuation:\n",
    "    text = text.replace(punctuation, '') \n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3b33e2",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "081b9094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' football is my passion i love to play with footballs who else loves football'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4d7b8faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['football',\n",
       " 'is',\n",
       " 'my',\n",
       " 'passion',\n",
       " 'i',\n",
       " 'love',\n",
       " 'to',\n",
       " 'play',\n",
       " 'with',\n",
       " 'footballs',\n",
       " 'who',\n",
       " 'else',\n",
       " 'loves',\n",
       " 'football']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "word_tokens = word_tokenize(text) \n",
    "\n",
    "word_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a4212e",
   "metadata": {},
   "source": [
    "## Stop-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d4c50206",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "stop_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cec00e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['football',\n",
       " 'passion',\n",
       " 'love',\n",
       " 'play',\n",
       " 'footballs',\n",
       " 'else',\n",
       " 'loves',\n",
       " 'football']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [w for w in word_tokens if not w in stop_words] \n",
    "  \n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a54856",
   "metadata": {},
   "source": [
    "## Stemming & Lemmatizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3474bb2f",
   "metadata": {},
   "source": [
    "### Setemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c69bd510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['footbal', 'passion', 'love', 'play', 'footbal', 'els', 'love', 'footbal']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "stemmed = [stemmer.stem(word) for word in text]\n",
    "\n",
    "stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e09f09",
   "metadata": {},
   "source": [
    "### Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e9d82277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['football', 'passion', 'love', 'play', 'football', 'else', 'love', 'football']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemmatized = [lemmatizer.lemmatize(word) for word in text]\n",
    "\n",
    "text = lemmatized\n",
    "\n",
    "lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7fce626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hang'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"hanging\",\"v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020abd38",
   "metadata": {},
   "source": [
    "# Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e847e3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['i love football',\n",
    "         'football is a game i love',\n",
    "        'football football football']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb513beb",
   "metadata": {},
   "source": [
    "## Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b30492d",
   "metadata": {},
   "source": [
    "Use _sklearn.feature_extraction.text.<mark><b>CountVectorizer</b></mark>_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5e26a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect_bow = CountVectorizer()\n",
    "\n",
    "X = vect_bow.fit_transform(texts).toarray() # CountVectorize take in input a list of texts \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0804a198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['football', 'game', 'is', 'love']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_bow.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "30f2112e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>football</th>\n",
       "      <th>game</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   football  game  is  love\n",
       "0         1     0   0     1\n",
       "1         1     1   1     1\n",
       "2         3     0   0     0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(X,columns=vect_bow.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afdd481",
   "metadata": {},
   "source": [
    "## Tf-Idf representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0e97d4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i love football', 'football is a game i love', 'football football football']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d875f13",
   "metadata": {},
   "source": [
    "Use _sklearn.feature_extraction.text.<mark><b>TfidfVectorizer</b></mark>_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ca906832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x4 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "texts = ['i love football',\n",
    "         'football is a game i love',\n",
    "        'football football football']\n",
    "\n",
    "tf_idf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = tf_idf_vectorizer.fit_transform(texts) # \n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04ca29a",
   "metadata": {},
   "source": [
    "To Vizualize The data we can use `.toarray`. But as input to model it is better to keep the data <mark><b>sparsed</b></mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "134d1893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>football</th>\n",
       "      <th>game</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.613356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.789807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.345205</td>\n",
       "      <td>0.584483</td>\n",
       "      <td>0.584483</td>\n",
       "      <td>0.444514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   football      game        is      love\n",
       "0  0.613356  0.000000  0.000000  0.789807\n",
       "1  0.345205  0.584483  0.584483  0.444514\n",
       "2  1.000000  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X.toarray(),columns=tf_idf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af36f062",
   "metadata": {},
   "source": [
    "### `max_df`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ec7ad8",
   "metadata": {},
   "source": [
    "Used to exclude <mark>\"corpus specific stopwords\"</mark>, words that are `very frequent` in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d2520d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i love football', 'football is a game i love', 'football football football']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6ea180fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.622766</td>\n",
       "      <td>0.622766</td>\n",
       "      <td>0.47363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       game        is     love\n",
       "0  0.000000  0.000000  1.00000\n",
       "1  0.622766  0.622766  0.47363\n",
       "2  0.000000  0.000000  0.00000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_idf_vectorizer = TfidfVectorizer(max_df = 0.8)\n",
    "\n",
    "X = tf_idf_vectorizer.fit_transform(texts)\n",
    "\n",
    "X.toarray()\n",
    "\n",
    "pd.DataFrame(X.toarray(),columns = tf_idf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccbec93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89148190",
   "metadata": {},
   "source": [
    "<big>👉 Particularly useful to remove words that are so frequent they have little predictive power.\n",
    "\n",
    "Example: When classifying texts into topics Basketball or football, the word \"ball\" will appear often, but won't be useful to predict one or the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18131b6",
   "metadata": {},
   "source": [
    "### `min_df`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d03e687",
   "metadata": {},
   "source": [
    "Used to <mark>exclude words that are very infrequent</mark> in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dc857ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i love football', 'football is a game i love', 'football football football']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "beab7c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>football</th>\n",
       "      <th>love</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.613356</td>\n",
       "      <td>0.789807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.613356</td>\n",
       "      <td>0.789807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   football      love\n",
       "0  0.613356  0.789807\n",
       "1  0.613356  0.789807\n",
       "2  1.000000  0.000000"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer(min_df = 0.5)\n",
    "\n",
    "X = tf_idf_vectorizer.fit_transform(texts)\n",
    "\n",
    "X.toarray()\n",
    "\n",
    "pd.DataFrame(X.toarray(),columns = tf_idf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4355f0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6732ee5d",
   "metadata": {},
   "source": [
    "<big>👉 Particularly useful to remove typos or text anomalies missed during preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc84053",
   "metadata": {},
   "source": [
    "### `max_features`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc2d754",
   "metadata": {},
   "source": [
    "Used to specify the <mark>number of features to keep</mark> when vectorizing. It will retain the top features according to count or tf-idf score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e15e3a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i love football', 'football is a game i love', 'football football football']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f8a21b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.622766</td>\n",
       "      <td>0.622766</td>\n",
       "      <td>0.47363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       game        is     love\n",
       "0  0.000000  0.000000  1.00000\n",
       "1  0.622766  0.622766  0.47363\n",
       "2  0.000000  0.000000  0.00000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer(max_df = 0.8)\n",
    "\n",
    "X = tf_idf_vectorizer.fit_transform(texts)\n",
    "\n",
    "X.toarray()\n",
    "\n",
    "pd.DataFrame(X.toarray(),columns = tf_idf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cbcfd3",
   "metadata": {},
   "source": [
    "<big>👉 Particularly useful to reduce the dimension of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6608d1e1",
   "metadata": {},
   "source": [
    "## N-Gram representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e4c190ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts =  ['i do not love football',\n",
    "         'i love football not basketball']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f70f433f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>do not</th>\n",
       "      <th>football not</th>\n",
       "      <th>love football</th>\n",
       "      <th>not basketball</th>\n",
       "      <th>not love</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.631667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631667</td>\n",
       "      <td>0.449436</td>\n",
       "      <td>0.631667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     do not  football not  love football  not basketball  not love\n",
       "0  0.631667      0.000000       0.449436        0.000000  0.631667\n",
       "1  0.000000      0.631667       0.449436        0.631667  0.000000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer(ngram_range = (2,2))\n",
    "\n",
    "X = tf_idf_vectorizer.fit_transform(texts)\n",
    "\n",
    "X.toarray()\n",
    "\n",
    "pd.DataFrame(X.toarray(),columns = tf_idf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47b3ec3",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9a2f11",
   "metadata": {},
   "source": [
    "### Vocabulary Richness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "896206e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i do not love football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i love football not basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Football football FootBall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text\n",
       "0          i do not love football\n",
       "1  i love football not basketball\n",
       "2      Football football FootBall"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(['i do not love football',\n",
    "                     'i love football not basketball',\n",
    "                    'Football football FootBall'],columns=['text'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "99c2e9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i do not love football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i love football not basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Football football FootBall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text\n",
       "0          i do not love football\n",
       "1  i love football not basketball\n",
       "2      Football football FootBall"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vocab_richness(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    total_length = len(tokens)\n",
    "    unique_words = set(tokens)\n",
    "    unique_word_length = len(unique_words)\n",
    "    return unique_word_length/total_length\n",
    "\n",
    "#data['vocab richness'] = data.text.apply(vocab_richness)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21ce414",
   "metadata": {},
   "source": [
    "# (Multinomial) Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "03b60c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"emails.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a8ae46",
   "metadata": {},
   "source": [
    "## Modelling Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "909dd13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9071229050279329"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(data.text)\n",
    "\n",
    "y = data.spam\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "nb_model.fit(X,y)\n",
    "\n",
    "nb_model.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc87859c",
   "metadata": {},
   "source": [
    "## Tuning vectorizer and model simultanously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f3d80d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'nb__alpha': (0.1, 1),\n",
       "                         'tfidf__ngram_range': ((1, 1), (2, 2))},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Set parameters to search\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': ((1,1), (2,2)),\n",
    "    'nb__alpha': (0.1,1),}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, \n",
    "                           verbose=1, scoring = \"accuracy\", \n",
    "                           refit=True, cv=5)\n",
    "\n",
    "grid_search.fit(data.text,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "87bf4e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nb__alpha': 0.1, 'tfidf__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "34aa088c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9881289771904556"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf03eba",
   "metadata": {},
   "source": [
    "## Combining vectorizer output and engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ff9d94d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>vocab_richness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.427692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.806818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.595960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.792453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam  vocab_richness\n",
       "0  Subject: naturally irresistible your corporate...     1        0.427692\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1        0.733333\n",
       "2  Subject: unbelievable new homes made easy  im ...     1        0.806818\n",
       "3  Subject: 4 color printing special  request add...     1        0.595960\n",
       "4  Subject: do not have money , get software cds ...     1        0.792453"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['vocab_richness'] = data.text.apply(vocab_richness)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ba2827c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "column_trans = ColumnTransformer([('vec', CountVectorizer(), 'text')]\n",
    "                                 , remainder='passthrough')\n",
    "\n",
    "X_combined = column_trans.fit_transform(data[['text','vocab_richness']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e1322a",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "809cea6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('95', 12.792048567001473), ('save', 9.245107638642253), ('andmanyother', 8.629491354823395), ('localized', 6.996871103699615), ('worldwide', 6.624492528316986), ('over', 6.606029188783462), ('oniine', 6.345210356476206), ('total', 6.193714127809999), ('nice', 5.805118320372363), ('mx', 5.7851711549598095)]\n",
      "Topic 1:\n",
      "[('the', 520.4368076760244), ('to', 466.72234261522254), ('and', 319.4884528513079), ('you', 291.7948850733383), ('of', 276.17145586075304), ('ect', 240.6488094654753), ('for', 227.45001056459006), ('in', 227.30945650197177), ('enron', 218.06561602113126), ('your', 188.58332206421363)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "vectorizer = TfidfVectorizer().fit(data['text'])\n",
    "\n",
    "data_vectorized = vectorizer.transform(data['text'])\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components=2).fit(data_vectorized)\n",
    "\n",
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-10 - 1:-1]])\n",
    "        \n",
    "\n",
    "print_topics(lda_model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0bf38f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0 : 0.17059808968716306\n",
      "topic 1 : 0.8294019103128369\n"
     ]
    }
   ],
   "source": [
    "example = [\"rice var congratulations save upenn\"]\n",
    "\n",
    "example_vectorized = vectorizer.transform(example)\n",
    "\n",
    "lda_vectors = lda_model.transform(example_vectorized)\n",
    "\n",
    "print(\"topic 0 :\", lda_vectors[0][0])\n",
    "print(\"topic 1 :\", lda_vectors[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f96e46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
